/**
 * Analisador de Imagens com IA
 * 
 * Funcionalidades:
 * - OCR com Tesseract.js
 * - An√°lise visual com OpenAI Vision ou Claude
 * - Extra√ß√£o autom√°tica de dados
 * - Valida√ß√£o de dados extra√≠dos
 */

const Tesseract = require('tesseract.js');
const { OpenAI } = require('openai');
const fs = require('fs-extra');
const path = require('path');

// Inicializar OpenAI (se API key estiver dispon√≠vel)
let openai = null;
if (process.env.OPENAI_API_KEY) {
  openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  });
}

/**
 * Analisa imagem do teste com IA
 * @param {string} imagemPath - Caminho local ou buffer/base64 da imagem
 * @param {string} testType - Tipo de teste ('palografico', 'atencao', 'memoria')
 * @returns {Promise<object>} Dados extra√≠dos e an√°lise
 */
async function analisarImagemTeste(imagemPath, testType) {
  try {
    console.log(`üì∏ Iniciando an√°lise de imagem para teste ${testType}`);
    
    // 1. OCR com Tesseract
    const ocrResult = await extrairTextoOCR(imagemPath);
    console.log(`‚úÖ OCR conclu√≠do. Confian√ßa: ${ocrResult.confidence}%`);
    
    // 2. An√°lise visual com OpenAI Vision (se dispon√≠vel)
    let visionResult = null;
    if (openai) {
      try {
        visionResult = await analisarComVision(imagemPath, testType);
        console.log(`‚úÖ An√°lise visual conclu√≠da. Confian√ßa: ${visionResult.confidence}%`);
      } catch (error) {
        console.warn('‚ö†Ô∏è Erro na an√°lise visual (continuando com OCR):', error.message);
      }
    } else {
      console.log('‚ÑπÔ∏è OpenAI n√£o configurado. Usando apenas OCR.');
    }
    
    // 3. Extrair dados num√©ricos
    const dadosExtraidos = extrairDados(ocrResult, visionResult, testType);
    
    // 4. Calcular confian√ßa geral
    const confiancaIA = calcularConfianca(ocrResult, visionResult);
    
    return {
      ocr_extracted_text: ocrResult.text,
      ia_extracted_text: visionResult?.description || ocrResult.text,
      dadosExtraidos,
      confiancaIA,
      analiseCompleta: {
        status: 'success',
        ocr_confidence: ocrResult.confidence,
        vision_confidence: visionResult?.confidence || 0,
        message: 'An√°lise conclu√≠da com sucesso'
      }
    };
    
  } catch (erro) {
    console.error('‚ùå Erro ao analisar imagem:', erro);
    throw erro;
  }
}

/**
 * Extrai texto com Tesseract OCR
 * @param {string|Buffer} imagemPath - Caminho da imagem ou buffer/base64
 * @returns {Promise<object>} Texto extra√≠do e confian√ßa
 */
async function extrairTextoOCR(imagemPath) {
  try {
    console.log('üîç Iniciando OCR com Tesseract...');
    
    // Converter base64 para buffer se necess√°rio
    let imageData = imagemPath;
    if (typeof imagemPath === 'string' && imagemPath.startsWith('data:image')) {
      // Base64 data URL
      const base64Data = imagemPath.split(',')[1];
      imageData = Buffer.from(base64Data, 'base64');
    }
    
    const { data: { text, confidence } } = await Tesseract.recognize(
      imageData,
      'por', // Portugu√™s
      {
        logger: m => {
          if (m.status === 'recognizing text') {
            console.log(`üìä Progresso OCR: ${Math.round(m.progress * 100)}%`);
          }
        }
      }
    );
    
    console.log(`‚úÖ OCR conclu√≠do. Texto extra√≠do: ${text.length} caracteres`);
    
    return {
      text: text.trim(),
      confidence: Math.round(confidence),
      status: 'success'
    };
    
  } catch (erro) {
    console.error('‚ùå Erro OCR:', erro);
    return { 
      text: '', 
      confidence: 0,
      status: 'error',
      error: erro.message
    };
  }
}

/**
 * An√°lise com OpenAI Vision
 * @param {string|Buffer} imagemPath - Caminho ou buffer da imagem
 * @param {string} testType - Tipo de teste
 * @returns {Promise<object>} An√°lise da IA
 */
async function analisarComVision(imagemPath, testType) {
  try {
    if (!openai) {
      return {
        description: '',
        confidence: 0,
        status: 'not_configured',
        message: 'OpenAI n√£o configurado'
      };
    }
    
    console.log('üîç Iniciando an√°lise com OpenAI Vision...');
    
    // Preparar imagem para OpenAI
    let imageData = imagemPath;
    let imageFormat = 'png';
    
    if (typeof imagemPath === 'string') {
      if (imagemPath.startsWith('data:image')) {
        // Base64 data URL
        const base64Data = imagemPath.split(',')[1];
        imageData = Buffer.from(base64Data, 'base64');
        imageFormat = imagemPath.match(/data:image\/(\w+);/)?.[1] || 'png';
      } else if (fs.existsSync(imagemPath)) {
        // Caminho de arquivo
        imageData = fs.readFileSync(imagemPath);
        imageFormat = path.extname(imagemPath).slice(1) || 'png';
      }
    }
    
    // Converter para base64 para OpenAI
    const base64Image = imageData.toString('base64');
    const imageUrl = `data:image/${imageFormat};base64,${base64Image}`;
    
    // Prompt espec√≠fico por tipo de teste
    const prompts = {
      palografico: `Analise esta imagem de um teste Palogr√°fico. Identifique:
        1. N√∫mero de palos por minuto (5 minutos)
        2. Tamanho m√©dio dos palos em mm
        3. Dist√¢ncia entre palos
        4. Irregularidades (inclina√ß√£o, press√£o, margens)
        Retorne apenas n√∫meros e dados objetivos no formato JSON:
        {"tempos": [min1, min2, min3, min4, min5], "tamanho_medio": X, "distancia_media": Y, "irregularidades": {...}}`,
      
      atencao: `Analise esta imagem de um teste de aten√ß√£o (AC ou similar). Identifique:
        1. N√∫mero de acertos
        2. N√∫mero de erros
        3. N√∫mero de omiss√µes
        Retorne apenas n√∫meros no formato JSON:
        {"acertos": X, "erros": Y, "omissoes": Z}`,
      
      memoria: `Analise esta imagem de um teste de mem√≥ria. Identifique:
        1. Evoca√ß√£o imediata
        2. Evoca√ß√£o tardia
        3. Reten√ß√£o
        4. Reconhecimento
        Retorne apenas n√∫meros no formato JSON:
        {"evocacao_imediata": X, "evocacao_tardia": Y, "retencao": Z, "reconhecimento": W}`
    };
    
    const response = await openai.chat.completions.create({
      model: "gpt-4-vision-preview",
      messages: [
        {
          role: "user",
          content: [
            { type: "text", text: prompts[testType] || prompts.atencao },
            {
              type: "image_url",
              image_url: {
                url: imageUrl
              }
            }
          ]
        }
      ],
      max_tokens: 500
    });
    
    const description = response.choices[0]?.message?.content || '';
    
    // Tentar extrair JSON da resposta
    let parsedData = null;
    try {
      const jsonMatch = description.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        parsedData = JSON.parse(jsonMatch[0]);
      }
    } catch (e) {
      console.warn('N√£o foi poss√≠vel parsear JSON da resposta da IA');
    }
    
    return {
      description,
      parsedData,
      confidence: 85, // Confian√ßa padr√£o da OpenAI Vision
      status: 'success'
    };
    
  } catch (erro) {
    console.error('‚ùå Erro Vision AI:', erro);
    return { 
      description: '', 
      confidence: 0,
      status: 'error',
      error: erro.message
    };
  }
}

/**
 * Extrai dados num√©ricos das an√°lises
 * @param {object} ocrResult - Resultado do OCR
 * @param {object} visionResult - Resultado da an√°lise visual
 * @param {string} testType - Tipo de teste
 * @returns {object} Dados extra√≠dos
 */
function extrairDados(ocrResult, visionResult, testType) {
  const dados = {};
  
  // Priorizar dados da Vision AI (mais confi√°vel)
  if (visionResult?.parsedData) {
    Object.assign(dados, visionResult.parsedData);
  }
  
  // Complementar com OCR se necess√°rio
  const texto = ocrResult.text || '';
  const numerosEncontrados = texto.match(/\d+/g) || [];
  
  if (testType === 'palografico') {
    // Buscar padr√µes de tempos/palos
    const palosMatch = texto.match(/(\d+)\s*(palos?|tra√ßos?|pontos?)/gi);
    if (palosMatch && palosMatch.length >= 5 && !dados.tempos) {
      dados.tempos = palosMatch.slice(0, 5).map(m => parseInt(m.match(/\d+/)[0]));
    }
    
    // Buscar tamanhos
    const tamanhosMatch = texto.match(/tamanho[\s:]*(\d+[\.,]\d*)/gi);
    if (tamanhosMatch && !dados.tamanho_medio) {
      dados.tamanho_medio = parseFloat(tamanhosMatch[0].replace(/[^\d,.]/g, '').replace(',', '.'));
    }
    
    // Buscar dist√¢ncias
    const distanciasMatch = texto.match(/dist[√¢a]ncia[\s:]*(\d+[\.,]\d*)/gi);
    if (distanciasMatch && !dados.distancia_media) {
      dados.distancia_media = parseFloat(distanciasMatch[0].replace(/[^\d,.]/g, '').replace(',', '.'));
    }
    
  } else if (testType === 'atencao') {
    // Extrair n√∫meros de acertos, erros, omiss√µes
    if (numerosEncontrados.length >= 3 && !dados.acertos) {
      dados.acertos = parseInt(numerosEncontrados[0]);
      dados.erros = parseInt(numerosEncontrados[1]);
      dados.omissoes = parseInt(numerosEncontrados[2]);
    }
  } else if (testType === 'memoria') {
    // Extrair dados de mem√≥ria
    if (numerosEncontrados.length >= 2 && !dados.evocacao_imediata) {
      dados.evocacao_imediata = parseInt(numerosEncontrados[0]);
      dados.evocacao_tardia = parseInt(numerosEncontrados[1]);
      if (numerosEncontrados.length >= 3) {
        dados.retencao = parseInt(numerosEncontrados[2]);
      }
      if (numerosEncontrados.length >= 4) {
        dados.reconhecimento = parseInt(numerosEncontrados[3]);
      }
    }
  }
  
  return dados;
}

/**
 * Calcula confian√ßa geral da an√°lise
 */
function calcularConfianca(ocrResult, visionResult) {
  if (visionResult && visionResult.confidence > 0) {
    // Se temos Vision AI, usar m√©dia ponderada
    return Math.round((ocrResult.confidence * 0.3 + visionResult.confidence * 0.7));
  }
  // Caso contr√°rio, usar apenas OCR
  return ocrResult.confidence || 0;
}

/**
 * Compara dados extra√≠dos com an√°lise manual
 * @param {object} dadosExtraidos - Dados extra√≠dos pela IA
 * @param {object} dadosManual - Dados inseridos manualmente
 * @returns {object} Compara√ß√£o com diferen√ßas
 */
function compararComManual(dadosExtraidos, dadosManual) {
  const comparacao = {
    match_total: true,
    diferencas: [],
    precisao: 100
  };
  
  let totalCampos = 0;
  let camposCorretos = 0;
  
  for (const chave in dadosExtraidos) {
    if (dadosManual[chave] !== undefined) {
      totalCampos++;
      const diferenca = Math.abs(dadosExtraidos[chave] - dadosManual[chave]);
      if (diferenca > 0) {
        comparacao.match_total = false;
        comparacao.diferencas.push({
          campo: chave,
          extraido: dadosExtraidos[chave],
          manual: dadosManual[chave],
          diferenca
        });
      } else {
        camposCorretos++;
      }
    }
  }
  
  if (totalCampos > 0) {
    comparacao.precisao = Math.round((camposCorretos / totalCampos) * 100);
  }
  
  return comparacao;
}

module.exports = {
  analisarImagemTeste,
  extrairTextoOCR,
  analisarComVision,
  extrairDados,
  compararComManual
};
